# Prometheus Metrics

The AIQ backend exposes Prometheus-compatible metrics at `/v1/metrics` for monitoring and observability.

## Quick Start

### 1. Enable Metrics

Add to your `.env` file:

```bash
# Enable OpenTelemetry metrics
OTEL_ENABLED=true
OTEL_METRICS_ENABLED=true

# Enable Prometheus metrics endpoint
PROMETHEUS_METRICS_ENABLED=true
```

### 2. Access Metrics

```bash
curl http://localhost:8000/v1/metrics
```

### 3. Configure Prometheus

Add to your `prometheus.yml`:

```yaml
scrape_configs:
  - job_name: 'aiq-backend'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/v1/metrics'
```

## Available Metrics

### HTTP Metrics

These metrics track all HTTP requests to the backend API.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `http_server_requests` | Counter | Total HTTP requests | `http.method`, `http.route`, `http.status_code` |
| `http_server_request_duration` | Histogram | HTTP request latency (seconds) | `http.method`, `http.route`, `http.status_code` |

**Example queries:**

```promql
# Request rate per endpoint
rate(http_server_requests[5m])

# 95th percentile request latency
histogram_quantile(0.95, rate(http_server_request_duration_bucket[5m]))

# Error rate (4xx and 5xx)
rate(http_server_requests{http_status_code=~"4..|5.."}[5m])
```

### Database Metrics

Track database query performance.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `db_query_duration` | Histogram | Database query duration (seconds) | `db.operation`, `db.table` |

**Example queries:**

```promql
# Slowest database queries by table
histogram_quantile(0.99, rate(db_query_duration_bucket[5m])) by (db_table)

# Query rate by operation type
rate(db_query_duration_count[5m]) by (db_operation)
```

### Test Session Metrics

Track cognitive test sessions throughout their lifecycle.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `test_sessions_active` | Gauge | Current number of in-progress test sessions | - |
| `test_sessions_started` | Counter | Total test sessions started | `test.adaptive`, `test.question_count` |
| `test_sessions_completed` | Counter | Total test sessions completed | `test.adaptive`, `test.question_count` |
| `test_sessions_abandoned` | Counter | Total test sessions abandoned | `test.adaptive`, `test.questions_answered` |

**Example queries:**

```promql
# Active test sessions right now
test_sessions_active

# Test completion rate (last hour)
rate(test_sessions_completed[1h]) / rate(test_sessions_started[1h])

# Abandonment rate by adaptive vs fixed-form
rate(test_sessions_abandoned[1h]) by (test_adaptive)

# Average questions answered before abandonment
avg(test_sessions_abandoned{test_questions_answered!=""}) by (test_adaptive)
```

### Question Metrics

Track AI-generated questions and question serving.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `questions_generated` | Counter | Total questions generated by AI | `question.type`, `question.difficulty` |
| `questions_served` | Counter | Total questions served to users | `test.adaptive` |

**Example queries:**

```promql
# Question generation rate by type
rate(questions_generated[1h]) by (question_type)

# Question distribution by difficulty
sum(questions_generated) by (question_difficulty)

# Questions served per test session
rate(questions_served[1h]) / rate(test_sessions_started[1h])
```

### User Metrics

Track user lifecycle events.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `users_registrations` | Counter | Total user registrations | - |

**Example queries:**

```promql
# New user registrations per day
increase(users_registrations[24h])

# Weekly registration trend
sum_over_time(increase(users_registrations[24h])[7d:24h])
```

### Error Metrics

Track application errors and exceptions.

| Metric | Type | Description | Labels |
|--------|------|-------------|--------|
| `app_errors` | Counter | Application errors | `error.type`, `http.route` |

**Example queries:**

```promql
# Error rate by endpoint
rate(app_errors[5m]) by (http_route)

# Most common error types
topk(5, rate(app_errors[1h]) by (error_type))

# Error percentage of total requests
rate(app_errors[5m]) / rate(http_server_requests[5m]) * 100
```

## Prometheus Configuration

### Basic Scraping

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'aiq-backend'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/v1/metrics'
```

### Production Configuration

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'aiq-backend-production'
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets: ['aiq-backend-production.up.railway.app:443']
    metrics_path: '/v1/metrics'
    scheme: https
    # Optional: Add service discovery for dynamic environments
    # relabel_configs:
    #   - source_labels: [__address__]
    #     target_label: instance
    #     replacement: 'aiq-backend-production'
```

### With Authentication

If your metrics endpoint requires authentication:

```yaml
scrape_configs:
  - job_name: 'aiq-backend'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/v1/metrics'
    bearer_token: 'your-metrics-token'
    # OR use basic auth:
    # basic_auth:
    #   username: 'metrics'
    #   password: 'your-password'  # pragma: allowlist secret
```

## Grafana Integration

### Add Prometheus Data Source

1. In Grafana, go to **Configuration** â†’ **Data Sources**
2. Click **Add data source**
3. Select **Prometheus**
4. Set URL to your Prometheus server (e.g., `http://prometheus:9090`)
5. Click **Save & Test**

### Import Dashboard

Use the example dashboard configuration below or create your own.

### Example Dashboard

```json
{
  "dashboard": {
    "title": "AIQ Backend Metrics",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_server_requests[5m])",
            "legendFormat": "{{http_method}} {{http_route}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Request Latency (p95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_server_request_duration_bucket[5m]))",
            "legendFormat": "{{http_route}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Active Test Sessions",
        "targets": [
          {
            "expr": "test_sessions_active",
            "legendFormat": "Active Sessions"
          }
        ],
        "type": "stat"
      },
      {
        "title": "Test Completion Rate",
        "targets": [
          {
            "expr": "rate(test_sessions_completed[1h]) / rate(test_sessions_started[1h]) * 100",
            "legendFormat": "Completion Rate %"
          }
        ],
        "type": "gauge"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(app_errors[5m])",
            "legendFormat": "{{error_type}}"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

## Example Grafana Dashboard JSON

Save this to a file (e.g., `aiq-dashboard.json`) and import into Grafana:

```json
{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${DS_PROMETHEUS}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "rate(http_server_requests[5m])",
          "legendFormat": "{{http_method}} {{http_route}}",
          "refId": "A"
        }
      ],
      "title": "Request Rate",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${DS_PROMETHEUS}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 10
              },
              {
                "color": "red",
                "value": 50
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 2,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ],
          "fields": ""
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "targets": [
        {
          "expr": "test_sessions_active",
          "legendFormat": "Active Sessions",
          "refId": "A"
        }
      ],
      "title": "Active Test Sessions",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${DS_PROMETHEUS}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 1
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 3,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(http_server_request_duration_bucket[5m]))",
          "legendFormat": "p95 {{http_route}}",
          "refId": "A"
        }
      ],
      "title": "Request Latency (p95)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${DS_PROMETHEUS}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 0.01
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "rate(test_sessions_completed[1h]) / rate(test_sessions_started[1h])",
          "legendFormat": "Completion Rate",
          "refId": "A"
        }
      ],
      "title": "Test Completion Rate",
      "type": "timeseries"
    }
  ],
  "refresh": "10s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["aiq", "backend"],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "AIQ Backend Metrics",
  "uid": "aiq-backend",
  "version": 1,
  "weekStart": ""
}
```

## Alerting Rules

Create alerting rules in Prometheus for critical metrics:

```yaml
# prometheus-rules.yml
groups:
  - name: aiq-backend-alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: rate(app_errors[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec"

      # High latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_server_request_duration_bucket[5m])) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High request latency detected"
          description: "95th percentile latency is {{ $value }}s"

      # Low test completion rate
      - alert: LowTestCompletionRate
        expr: rate(test_sessions_completed[1h]) / rate(test_sessions_started[1h]) < 0.7
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Test completion rate is low"
          description: "Completion rate is {{ $value | humanizePercentage }}"

      # Many abandoned tests
      - alert: HighAbandonmentRate
        expr: rate(test_sessions_abandoned[1h]) / rate(test_sessions_started[1h]) > 0.3
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "High test abandonment rate"
          description: "Abandonment rate is {{ $value | humanizePercentage }}"
```

## Troubleshooting

### Metrics Endpoint Returns 503

**Cause:** Metrics are not enabled or OpenTelemetry failed to initialize.

**Solution:**

1. Check `.env` configuration:
   ```bash
   OTEL_ENABLED=true
   OTEL_METRICS_ENABLED=true
   PROMETHEUS_METRICS_ENABLED=true
   ```

2. Check application logs for initialization errors:
   ```bash
   grep -i "metrics" logs/app.log
   ```

3. Verify packages are installed:
   ```bash
   pip list | grep -E "opentelemetry|prometheus"
   ```

### No Metrics Showing Up

**Cause:** Prometheus exporter not initialized or no activity yet.

**Solution:**

1. Generate some traffic to the backend
2. Wait for the metrics export interval (60 seconds by default)
3. Check if the exporter is initialized:
   ```bash
   curl http://localhost:8000/v1/metrics | grep -c "http_server_requests"
   ```

### Metrics Seem Stale

**Cause:** Export interval is too long or scrape interval mismatch.

**Solution:**

1. Reduce export interval in `.env`:
   ```bash
   OTEL_METRICS_EXPORT_INTERVAL_MILLIS=15000  # 15 seconds
   ```

2. Ensure Prometheus scrape interval matches or is less than export interval

## Best Practices

### Metric Naming

- Use underscores for word separation (e.g., `http_server_requests`)
- Include units in the name when ambiguous (e.g., `duration_seconds`)
- Use consistent prefixes by domain (e.g., `test_`, `http_`, `db_`)

### Labels

- Keep cardinality low (avoid high-cardinality labels like user IDs)
- Use labels for dimensions you want to filter/group by
- Prefer fewer labels with meaningful values

### Retention

- Prometheus default retention is 15 days
- For production, configure longer retention:
  ```bash
  prometheus --storage.tsdb.retention.time=90d
  ```

### Performance

- Monitor Prometheus memory usage as metric count grows
- Use recording rules for expensive queries
- Consider using remote storage for long-term retention

## Further Reading

- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Dashboards](https://grafana.com/docs/grafana/latest/dashboards/)
- [OpenTelemetry Metrics](https://opentelemetry.io/docs/concepts/signals/metrics/)
- [Prometheus Best Practices](https://prometheus.io/docs/practices/naming/)
