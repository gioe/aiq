# Generator Model Configuration
# Maps question types to specific LLM providers for question generation
#
# Each question type is assigned to the provider that performs best
# on relevant benchmarks for that cognitive domain. This is the same
# mapping used for judging (Option A: specialists do both).
#
# Configuration Structure:
#   question_type:
#     provider: Provider name ("openai", "anthropic", "google", "xai")
#     rationale: Explanation of why this provider was chosen
#     fallback: Fallback provider if primary is unavailable

version: "1.0"

generators:
  math:
    provider: "xai"
    rationale: "Exceptional math performance: GSM8K (95.2%), AIME 2024 (100%), USAMO 2025 (61.9%). Grok 4 demonstrates world-class mathematical reasoning."
    fallback: "anthropic"

  logic:
    provider: "anthropic"
    model: "claude-sonnet-4-5-20250929"
    rationale: "Claude Sonnet 4.5 (Jan 2026): SWE-bench verified 77-82%, GPQA Diamond 83.4%, HumanEval >95%. Major upgrade from Claude 3.5 Sonnet (49% SWE-bench) for logic and reasoning tasks."
    fallback: "openai"

  pattern:
    provider: "google"
    model: "gemini-3-pro-preview"
    rationale: "ARC-AGI-2: 31.1%, GPQA Diamond: 91.9%. Superior abstract pattern recognition. Updated Jan 2026."
    fallback: "anthropic"

  spatial:
    provider: "google"
    model: "gemini-3-pro-preview"
    rationale: "ARC-AGI-2: 31.1% (45.1% Deep Think), breakthrough spatial reasoning. Updated Jan 2026."
    fallback: "anthropic"

  verbal:
    provider: "anthropic"
    model: "claude-sonnet-4-5-20250929"
    rationale: "Claude Sonnet 4.5 (Jan 2026): MMLU 89%, HellaSwag ~95%. Enhanced language understanding and generation with superior NLP performance."
    fallback: "openai"

  memory:
    provider: "anthropic"
    rationale: "Claude Sonnet 4.5 (Jan 2026): MMLU 89% with 200K token context. Strong knowledge benchmarks with massive context for memory tasks."
    fallback: "openai"

# Default generator (fallback for unknown question types)
default_generator:
  provider: "openai"
  rationale: "General-purpose fallback generator"

# Enable/disable specialist routing
# When false, falls back to round-robin distribution
use_specialist_routing: true

# Notes:
# - Provider names must match: "openai", "anthropic", "google", or "xai"
# - Fallback is used when primary provider's circuit breaker is open
# - This config aligns with judges.yaml for Option A (specialists do both)
