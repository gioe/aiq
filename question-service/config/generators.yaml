# Generator Model Configuration
# Maps question types to specific LLM providers for question generation
#
# Each question type is assigned to the provider that performs best
# on relevant benchmarks for that cognitive domain. This is the same
# mapping used for judging (Option A: specialists do both).
#
# Configuration Structure:
#   question_type:
#     provider: Provider name ("openai", "anthropic", "google", "xai")
#     model: Exact API model identifier (must match provider SDK expectations)
#     rationale: Explanation of why this provider was chosen
#     fallback: Fallback provider if primary is unavailable
#
# IMPORTANT - Model Naming Convention:
#   Model identifiers MUST match the exact strings used by each provider's API:
#   - Anthropic: claude-opus-4-5-20251101, claude-sonnet-4-5-20250929, etc.
#   - Google: gemini-3-pro-preview, gemini-3-flash-preview, gemini-2.5-pro, etc.
#   - OpenAI: gpt-5.2, gpt-4-turbo, o4-mini, etc.
#   - xAI: grok-4, grok-3, grok-beta
#   See each provider's get_available_models() for the full list.

version: "1.0"

generators:
  math:
    provider: "xai"
    model: "grok-4"
    rationale: "Exceptional math performance: GSM8K (95.2%), AIME 2024 (100%), USAMO 2025 (61.9%). Grok 4 demonstrates world-class mathematical reasoning."
    fallback: "anthropic"

  logic:
    provider: "anthropic"
    model: "claude-sonnet-4-5-20250929"
    rationale: "Claude Sonnet 4.5 (Jan 2026): SWE-bench verified 77-82%, GPQA Diamond 83.4%, HumanEval >95%. Major upgrade from Claude 3.5 Sonnet (49% SWE-bench) for logic and reasoning tasks."
    fallback: "openai"

  pattern:
    provider: "google"
    model: "gemini-3-pro-preview"
    rationale: "ARC-AGI-2: 31.1%, GPQA Diamond: 91.9%. Superior abstract pattern recognition. Updated Jan 2026. Using preview identifier per Google API docs."
    fallback: "anthropic"

  spatial:
    provider: "google"
    model: "gemini-3-pro-preview"
    rationale: "ARC-AGI-2: 31.1% (standard mode), breakthrough spatial reasoning. Deep Think mode (45.1%) not currently enabled. Updated Jan 2026. Using preview identifier per Google API docs."
    fallback: "anthropic"

  verbal:
    provider: "anthropic"
    model: "claude-sonnet-4-5-20250929"
    rationale: "Claude Sonnet 4.5 (Jan 2026): MMLU 89%, HellaSwag ~95%. Enhanced language understanding and generation with superior NLP performance."
    fallback: "openai"

  memory:
    provider: "anthropic"
    model: "claude-sonnet-4-5-20250929"
    rationale: "Claude Sonnet 4.5 (Jan 2026): MMLU 89% with 200K token context. Strong knowledge benchmarks with massive context for memory tasks."
    fallback: "openai"

# Default generator (fallback for unknown question types)
default_generator:
  provider: "openai"
  model: "gpt-4-turbo"
  rationale: "General-purpose fallback generator"

# Enable/disable specialist routing
# When false, falls back to round-robin distribution
use_specialist_routing: true

# Notes:
# - Provider names must match: "openai", "anthropic", "google", or "xai"
# - Fallback is used when primary provider's circuit breaker is open
# - This config aligns with judges.yaml for Option A (specialists do both)
