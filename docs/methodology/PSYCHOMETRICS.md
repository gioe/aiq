# Psychometric Foundations

This document covers the established scientific foundations of IQ testing methodology, including question categories, development processes, scoring formulas, and validation standards. This research informs AIQ's approach to cognitive assessment.

---

## Table of Contents

1. [Question Categories and Cognitive Domains](#1-question-categories-and-cognitive-domains)
2. [Test Development Process](#2-test-development-process)
3. [Statistical Analysis Methods](#3-statistical-analysis-methods)
4. [Standardization and Norming](#4-standardization-and-norming)
5. [Reliability and Validity Standards](#5-reliability-and-validity-standards)
6. [Fairness and Ethical Considerations](#6-fairness-and-ethical-considerations)
7. [Application to AIQ](#7-application-to-aiq)
8. [References](#8-references)

---

## 1. Question Categories and Cognitive Domains

### 1.1 Primary Cognitive Domains

IQ tests measure intelligence across well-established cognitive domains:

| Domain | Description | Example Tasks |
|--------|-------------|---------------|
| **Verbal Comprehension** | Reading, language, vocabulary | Word meanings, verbal analogies, abstract verbal reasoning |
| **Perceptual/Spatial Reasoning** | Mental manipulation of objects | 3D rotation, spatial visualization, visual pattern recognition |
| **Working Memory** | Short-term retention and manipulation | Sequence recall, digit span, mental arithmetic |
| **Processing Speed** | Speed of cognitive processing | Visual scanning, rapid decision-making |
| **Mathematical Reasoning** | Quantitative problem-solving | Number relationships, mathematical logic |
| **Logical Reasoning** | Deductive and inductive reasoning | Syllogisms, pattern inference, conditional logic |

### 1.2 Fluid vs. Crystallized Intelligence

Intelligence is conceptually divided into two broad categories:

**Fluid Intelligence (Gf)**
- Ability to think logically and solve novel problems
- Independent of acquired knowledge
- Abstract reasoning and pattern recognition
- Peaks in early adulthood, gradually declines

**Crystallized Intelligence (Gc)**
- Acquired knowledge and skills
- Dependent on education and experience
- Vocabulary, facts, and procedures
- Tends to remain stable or increase with age

### 1.3 Question Types in Major IQ Tests

#### WAIS-IV (Wechsler Adult Intelligence Scale)

**Verbal Subtests:**
- Information: General knowledge questions
- Comprehension: Understanding of social rules and concepts
- Arithmetic: Mathematical word problems
- Digit Span: Repeat numbers forward/backward
- Similarities: Identify commonalities between concepts
- Vocabulary: Define words

**Performance/Perceptual Subtests:**
- Matrix Reasoning: Complete visual pattern matrices
- Block Design: Replicate patterns with blocks
- Picture Completion: Identify missing elements
- Digit Symbol: Copy symbols paired with numbers
- Symbol Search: Scan for target symbols

#### Stanford-Binet (5th Edition)

Five-factor structure:
- Fluid Reasoning
- Knowledge
- Quantitative Reasoning
- Visual-Spatial Processing
- Working Memory

#### Raven's Progressive Matrices

- 60 multiple-choice questions in 5 sets (A-E)
- Each set contains 12 items of increasing difficulty
- Pure pattern recognition and abstract reasoning
- Non-verbal, culturally neutral design

**Pattern Types:**
- Progression: Elements change systematically
- Rotation: Shapes rotate predictably
- Addition/Subtraction: Elements added or removed
- Transformation: Shapes transform according to rules
- Matrix completion: Identify missing piece in grid

---

## 2. Test Development Process

### 2.1 Theoretical Foundation

**Step 1: Choose Theoretical Framework**
- Spearman's g-factor (general intelligence)
- Cattell-Horn-Carroll (CHC) theory (hierarchical model)
- Gardner's multiple intelligences
- Sternberg's triarchic theory

The chosen theory guides which cognitive abilities to measure and test structure.

### 2.2 Test Construction

**Step 2: Define the Construct**
- Specify what aspect of intelligence is being measured
- Identify target cognitive domains
- Determine test purpose (clinical, educational, research)

**Step 3: Literature Review**
- Review existing tests and research
- Examine psychometric properties of similar assessments
- Identify gaps in current testing approaches

**Step 4: Item Generation**
- Create diverse questions covering different cognitive aspects
- Ensure items vary in difficulty to discriminate across ability levels
- Design questions with clear, unambiguous correct answers
- Include plausible distractors in multiple-choice items
- Aim for cultural neutrality and accessibility

### 2.3 Pilot Testing

**Step 5: Initial Testing**
- Administer test to small representative sample
- Gather feedback on clarity, difficulty, and relevance
- Identify problematic or ambiguous items
- Collect timing data for test administration

---

## 3. Statistical Analysis Methods

### 3.1 Classical Test Theory (CTT)

CTT analyzes:
- **Item Difficulty**: Percentage answering correctly (p-value)
- **Discrimination Index**: Correlation with total score
- **Internal Consistency**: Cronbach's alpha
- **Test-Retest Reliability**: Correlation between administrations

### 3.2 Item Response Theory (IRT)

Modern standard for test development, providing:

**Item Parameters:**
- **Difficulty (b)**: Ability level for 50% correct probability
- **Discrimination (a)**: How well item differentiates ability levels
- **Guessing (c)**: Probability of random correct response

**IRT Models:**
| Model | Parameters | Use Case |
|-------|------------|----------|
| 1-Parameter (Rasch) | Difficulty only | Simple, robust estimates |
| 2-Parameter | Difficulty + discrimination | Most common |
| 3-Parameter | + Guessing | Multiple-choice items |

**Advantages over CTT:**
- Person parameter invariance (scores independent of specific items)
- Item banking capabilities
- Adaptive testing possibilities
- Variable measurement error across ability levels
- Test information functions showing precision

### 3.3 Item Refinement Criteria

Items are refined or removed based on:
- Poor discrimination (low correlation with total score)
- Extreme difficulty (too easy or too hard)
- Ambiguous wording
- Differential item functioning across groups

---

## 4. Standardization and Norming

### 4.1 Norming Sample Requirements

**Sample Characteristics:**
- Large sample size (typically 2,000+ participants)
- Representative of target population demographics:
  - Age distribution
  - Gender balance
  - Ethnic diversity
  - Geographic representation
  - Educational background
  - Socioeconomic status

*Example: WAIS-IV standardized on 2,200 people aged 16-90*

### 4.2 Norm Development Process

1. Administer final test version to norming sample
2. Collect raw scores across entire sample
3. Transform raw scores to normalized distribution
4. Establish percentile ranks and standard scores
5. Create age-based norms
6. Develop continuous norming procedures

### 4.3 Types of Norms

| Type | Description |
|------|-------------|
| Percentile norms | Ranking relative to norming sample |
| Age norms | Account for developmental differences |
| Grade norms | For educational contexts |
| National vs. local | Population-specific standards |

### 4.4 Ongoing Maintenance

- Periodic renorming (every 10-15 years typically)
- Continuous item analysis and improvement
- Updates to reflect current research
- Recalibration to prevent Flynn Effect bias (scores increasing over time)

---

## 5. Reliability and Validity Standards

### 5.1 Reliability Standards

#### Internal Consistency (Cronbach's Alpha)

| Alpha Value | Interpretation |
|-------------|----------------|
| >= 0.90 | Excellent |
| >= 0.70 | Good |
| >= 0.60 | Minimum acceptable |
| Top IQ tests | 0.93-0.95 |

#### Test-Retest Reliability

| Correlation | Interpretation |
|-------------|----------------|
| > 0.9 | Excellent |
| > 0.7 | Good |
| > 0.4 (ICC) or > 0.3 (Pearson r) | Minimum acceptable |

*Note: Longer time intervals = lower correlations*

#### Standard Error of Measurement (SEM)

- Best modern tests: ~3 points
- Confidence intervals: typically +/-10 points

### 5.2 Validity Standards

#### Construct Validity
- Factor analysis confirms theoretical structure
- Convergent validity with related constructs
- Discriminant validity from unrelated constructs

#### Criterion Validity

| Type | Standard | Example |
|------|----------|---------|
| Concurrent | r > 0.70 | Correlation with established IQ tests |
| Predictive | r = 0.50-0.60 | Academic achievement prediction |

*High-quality tests show correlations of r = 0.76-0.86 with gold-standard cognitive tests*

#### Content Validity
- Expert panel review
- Alignment with theoretical framework
- Comprehensive domain coverage

---

## 6. Fairness and Ethical Considerations

### 6.1 Cultural Fairness

**Design Principles:**
- Minimize language-specific content for non-verbal tests
- Avoid culture-specific knowledge requirements
- Pilot test across diverse populations
- Differential Item Functioning (DIF) analysis to detect bias

*Raven's Progressive Matrices exemplifies cultural fairness: purely non-verbal, minimal cultural knowledge needed, administrable globally*

### 6.2 Accommodations

- Time extensions for processing speed differences
- Alternative formats for sensory impairments
- Language translations with validation
- Appropriate norms for special populations

### 6.3 Ethical Guidelines

- Informed consent required
- Qualified administrator required (training/certification)
- Results interpreted in context (not sole decision factor)
- Confidentiality maintained
- Misuse prevention (high-stakes decisions should use multiple measures)

### 6.4 Test Security

- Items kept confidential to prevent practice effects
- Limited public exposure of actual test content
- Secure administration environments
- Prevention of coaching that inflates scores artificially

---

## 7. Application to AIQ

### 7.1 Current Implementation Alignment

| Standard | AIQ Implementation |
|----------|-------------------|
| Question categories | Aligned with established cognitive domains (pattern, logic, spatial, math, verbal, memory) |
| Multi-evaluator approach | Multi-LLM generation mirrors expert committee development |
| Quality evaluation | Arbiter evaluation mimics psychometric review |
| Difficulty levels | Easy/medium/hard follows industry practice |
| Item uniqueness | Deduplication prevents item repetition |

### 7.2 Psychometric Features Implemented

- **Empirical difficulty calculation** (p-value from actual responses)
- **Item discrimination analysis** (point-biserial correlation)
- **Distractor analysis** for multiple-choice questions
- **Reliability estimation** (Cronbach's alpha, test-retest, split-half)
- **Standard Error of Measurement** with confidence intervals
- **Quality flagging** for problematic items

### 7.3 Realistic Expectations

**What AIQ Can Achieve:**
- Track cognitive performance over time
- Practice IQ-style questions across multiple domains
- Identify cognitive strengths and areas for growth
- Provide increasingly valid assessments as data accumulates

**Limitations:**
- Professional IQ tests take years to develop and validate
- Large norming samples (2,000+) are expensive and time-consuming
- Full construct validity requires extensive research
- Not equivalent to clinical IQ testing

### 7.4 Development Stages

| Stage | Focus |
|-------|-------|
| **MVP** | Question quality, diversity, infrastructure, initial data collection |
| **Growth** | Analyze performance data, IRT-based calibration, refine scoring, validation studies |
| **Mature** | Establish reliability evidence, publish psychometric properties, seek external validation |

---

## 8. References

### Foundational Tests
- Wechsler Adult Intelligence Scale (WAIS) technical manual
- Stanford-Binet Intelligence Scales documentation
- Raven's Progressive Matrices research papers

### Statistical Methods
- Item Response Theory (IRT) literature
- Classical Test Theory (CTT) foundations
- Factor analysis for intelligence research

### Theoretical Frameworks
- Spearman's g-factor theory
- Cattell-Horn-Carroll (CHC) theory
- Fluid vs. crystallized intelligence (Gf-Gc theory)

### Professional Standards
- APA Standards for Educational and Psychological Testing
- National Council on Measurement in Education (NCME)
- International Test Commission (ITC) guidelines

---

## Summary

The science of IQ testing is well-established and transparent in its methods, standards, and formulas. While specific test items are proprietary, the overall process, psychometric standards, and scoring methods are public knowledge.

AIQ follows established psychometric principles:
- Question categories align with cognitive science research
- Statistical validation methods match industry standards
- Quality controls ensure assessment integrity
- Continuous improvement based on empirical data

With proper data collection and analysis, AIQ can achieve meaningful cognitive assessment while being transparent about its limitations relative to professionally developed clinical instruments.
